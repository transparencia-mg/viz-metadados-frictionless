## Technical Approach  - What to look for

• A vision. The contractor needs to see the intended outcomes in a way that can act as a catalyst to the agency’s vision.
• Understands program goals. The vendor should have a clear grasp of what the agency is doing. There should be no serious misunderstandings of information that was described clearly in the RFQ.
• Experience developing open source software. 
• Collaboration and communication. The contractor expects the agency’s product owner to be a valuable, active team member. They also expect to communicate proactively about risks and roadblocks, so they can work as effectively as possible.
• Regular and ongoing user research to understand users’ goals and needs, and what to build that supports them. They will combine user research with usability testing to ensure that users can achieve their broader goals in using the software, and that it addresses their needs along the way. They plan to conduct user research, and test everything from rough prototypes to more polished software with actual users, throughout the entire design and development process.
• They follow a user-centered design process. They can explain how they make design decisions in relation to broader user goals and specific needs learned through their research. 
• The contractor focuses on automation, reliability, testability, infrastructure as code, and other core DevOps principles. The proposal refers to modern automation and deployment tooling like Jenkins, Puppet, Chef, Travis CI, CircleCI, Kubernetes, Terraform, 
AWS, and Heroku. 

#### Red flags
• Don’t seem to understand program goals. They seriously misunderstand information that was described clearly in the solicitation.
• Misidentifying the name of technologies in such a way that shows a lack of experience communicating about them (e.g. “we’ll index records with an Elasticsearch,” instead of “with Elasticsearch,” or “we recommend using JAVA,” instead of “Java”).
• Excessive complexity. 
• They shirk page-limit rules (tiny fonts, reduced leading, etc.) because they believe their technical approach to be so brilliant that it can’t possibly fit within the prescribed limit.
• Basing their solution on a fundamental misunderstanding of the agency’s needs that they should have understood.
• Proposing the use of arcane platforms and technologies, especially when those arcane platforms and technologies are contractor specialties.
• They never once mention the software’s accessibility, or do not identify how they will evaluate whether their software meets accessibility standards.
• They don’t consider, explicitly or implicitly, that user research will ultimately determine the approach, which in turn will dictate the technical approach.
• Uses terminology like “requirements will be collected from the business owner”; user needs should be uncovered through research and listed as user stories in the product backlog.
• They’re proposing to outsource what should be core competencies, e.g., DevOps or Javascript.
• They propose a process that includes working for long stretches of time without interacting with the agency and/or users.
• They describe the goal of research as being to “test the app with users,” “find problems,” or ask users what they “like,” “want,” or “might do” (shows that they draw conclusions based on what users say instead of observing and learning from users what they do).
• They use the term “user testing” instead of “usability testing” (not testing the user, testing the system’s functionality).
• They propose relying on focus groups, instead of structured, oneon-one research interviews or usability testing sessions.
• They prioritize aesthetics over usability and usefulness, and cannot explain why they made design decisions. 
• Don’t mention anything about secure code practices.
• Don’t demonstrate that testing is important.
• They propose long-term staff augmentation.

## Staffing Approach - What to look for

• A small number of team members, each providing a clear value. Everyone proposed has a purpose.
• Familiar with and demonstrate use of modern software languages (e.g. Python, Ruby, PHP, C#, Javascript).
• Familiar with and demonstrate use of web-based application programming interfaces (APIs), especially REST and GraphQL.
**• Experience using Git for software version control.
• The lead developer’s skill mix and experience cover much of the work that the agency’s project requires.
• If the developers have presences on social coding platforms (e.g., GitHub, GitLab, Bitbucket), how does their work look? What expertise is evident there? Do they have expertise that doesn’t appear in their qualifications, but their work reveals?**
• Staff qualifications support their claimed expertise. (For example, does the content strategist have any actual content strategy 
experience, or are they a project manager in sheep’s clothing?)
• The lead user researcher’s background indicates an understanding of how research can inform and shape strategy, design, and development; familiarity with a variety of research and testing methods; and experience deciding which method or methods to use based on the learning goals of the phase or needs of the project, and with recruiting users based on those goals and needs.
• The lead UX designer’s background demonstrates strong craft skills and experience in generating concepts based in overall strategy, user research, and user-centered design best practices; and experience communicating those concepts visually via a variety of methods including but not limited to sketching, wireframing, prototypes, and more polished mockups to use in research and to guide development. 
• Generally, the team is assigned to the project full-time and will not be splitting their time across other unrelated projects. There may be acceptable exceptions, such as for a scrum master or agile coach, but in general everyone should be fully staffed to the project. This is critical for developers, user researchers, designers, and all key personnel. 

#### Red flags
• Overstaffing the bid. A team that consists of people with far more experience than necessary or more people than necessary means that the contractor either doesn’t understand this way of working or is trying to over-staff the engagement.
• Proposing positions that do not belong in iterative development – business analysts, enterprise architects, delivery managers, etc.
• Poorly designed websites for the company, proposed subcontractor, or proposed staff qualifications. 
• Proposing antiquated software technologies that don’t have an active developer community (e.g. Cold Fusion, ASP, FoxPro).
• Lack of experience with test automation, aka DevOps, aka testdriven development (TDD).
• Insufficiently qualified lead developer.
• No apparent experience with usability research.
• No apparent experience with visual design.
• The flashiest team member is proposed to spend a tiny amount of time on the project.

**• Key skills don’t appear in any qualifications, such as:
° Platform migration 
° Agile development practices
° Automated (unit/integration/end-to-end) testing
° Continuous Integration and Continuous Deployment
° DevOps
° Refactoring to minimize technical debt
° Application Protocol Interface (API) development and documentation
° Open-source software development
° Cloud deployment
° Product management and strategy98 DE-RISKING GOVERNMENT TECHNOLOGY Deciding what to buy 99
° Usability research, such as (but not limited to) contextual inquiry, stakeholder interviews, and usability testing
° User experience design
° Sketching, wireframing, and/or prototyping, and user-task flow development
° Visual design
° Content design and copywriting
° Building and testing public-facing sites and tools**

• No actual technical staff, but “access to a database of resumes.”
• Proposed staff don’t currently work for the contractor, and there is no letter of intent from the proposed staff.
• Proposed staff qualifications are copied from the Internet, in large part or, more rarely, in whole.
• Key staff are not proposed to be 100% full time to the project, or the project is staffed with a number of partial FTE personnel. 

### Similar experience
18F often asks contractors to submit code repositories that 
demonstrate producing quality code that is in similar size, scope, and 
complexity to what the agency needs. If you do not have someone 
on your evaluation team that is familiar with code repositories, you 
should find one to serve as a technical advisor. 18F can support 
agencies with this need with a signed interagency agreement. 
Technical evaluations should look for
• Proper use of Git, commit changes with personal accounts (not organizational), use of a branching / merging strategy, informative comments, evidence of code reviews, and use of a CI/CD pipeline.
• Code that conforms well to the solicitation’s QASP.
• Git collaboration. Work was performed in a reasonable number of GitHub comments.
• Substantial projects. The projects were not created just to have something to point to for this RFQ.
• How they incorporate user feedback into their development process.
• Their tests are written well, and cover the supermajority of the code.
• Consistent, enforced code style.

## Programmatic evaluations should look for
• Work that is conceptually similar to the agency’s needs.
• Work that was centered on user needs, as opposed to leading with solutionism.
• Work that was completed by a team of a size that’s similar to the size of the team that they’re proposing.
• Design artifacts that show continuous and ongoing usability testing that indicate a user-centered approach to iterative design and 
development.

#### Red flags
• The cited projects bear little evidence that the contractor created them.
• The projects are trivial.
• There’s a finished product, but no code, or vice versa.
• The projects do not include good design artifacts and research plans.
